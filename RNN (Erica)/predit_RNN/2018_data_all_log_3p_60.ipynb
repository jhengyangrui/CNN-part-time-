{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 0  loss: 0.309277\n",
      "Number of iterations: 25  loss: 0.213668\n",
      "Number of iterations: 50  loss: 0.211139\n",
      "Number of iterations: 75  loss: 0.217761\n",
      "Number of iterations: 100  loss: 0.224542\n",
      "Number of iterations: 125  loss: 0.225728\n",
      "Number of iterations: 150  loss: 0.221822\n",
      "Number of iterations: 175  loss: 0.215277\n",
      "model_save:  model_save2\\modle.ckpt\n",
      "The train has finished\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "rnn_unit=10       #隱藏數量(自訂)\n",
    "input_size=7 #BICPRFM\n",
    "output_size=1 #YN\n",
    "lr=0.0001         #學習率\n",
    "#——————————————————import data ——————————————————————\n",
    "f=open('2018_data_all_log_3p.csv')\n",
    "df=pd.read_csv(f)     #讀入資料\n",
    "data=df.iloc[:,3:11].values  #取第3-10列(取頭不取尾)\n",
    "\n",
    "\n",
    "#獲取訓練集 (做標準化)\n",
    "def get_train_data(batch_size=6,time_step=3,train_begin=0,train_end=3960):\n",
    "    batch_index=[]\n",
    "    data_train=data[train_begin:train_end]\n",
    "    normalized_train_data=(data_train-np.mean(data_train,axis=0))/np.std(data_train,axis=0)  #標準化\n",
    "    train_x,train_y=[],[]   #訓練集\n",
    "    for i in range(len(normalized_train_data)-time_step):\n",
    "       if i % batch_size==0:\n",
    "           batch_index.append(i)\n",
    "       x=normalized_train_data[i:i+time_step,:7]\n",
    "       y=data_train[i:i+time_step,7,np.newaxis]\n",
    "       train_x.append(x.tolist())\n",
    "       train_y.append(y.tolist())\n",
    "    batch_index.append((len(normalized_train_data)-time_step))\n",
    "    return batch_index,train_x,train_y\n",
    "\n",
    "\n",
    "#測試集\n",
    "def get_test_data(time_step=3,test_begin=3960):\n",
    "    data_test=data[test_begin:]\n",
    "    mean=np.mean(data_test,axis=0)\n",
    "    std=np.std(data_test,axis=0)\n",
    "    normalized_test_data=(data_test-mean)/std  #標準化\n",
    "    size=(len(normalized_test_data)+time_step-1)//time_step  #有size個sample\n",
    "    test_x,test_y=[],[]\n",
    "    for i in range(size-1):\n",
    "       x=normalized_test_data[i*time_step:(i+1)*time_step,:7]\n",
    "       y=data_test[i*time_step:(i+1)*time_step,7]\n",
    "       test_x.append(x.tolist())\n",
    "       test_y.extend(y)\n",
    "    test_x.append((normalized_test_data[(i+1)*time_step:,:7]).tolist())\n",
    "    test_y.extend((data_test[(i+1)*time_step:,7]).tolist())\n",
    "    return mean,std,test_x,test_y\n",
    "\n",
    "\n",
    "#——————————————————定義神經網絡變量——————————————————\n",
    "#輸入層  輸出層權重  bias\n",
    "\n",
    "weights={\n",
    "         'in':tf.Variable(tf.random_normal([input_size,rnn_unit])),\n",
    "         'out':tf.Variable(tf.random_normal([rnn_unit,1]))\n",
    "        }\n",
    "biases={\n",
    "        'in':tf.Variable(tf.constant(0.1,shape=[rnn_unit,])),\n",
    "        'out':tf.Variable(tf.constant(0.1,shape=[1,]))\n",
    "       }\n",
    "\n",
    "#——————————————————定義lstm——————————————————\n",
    "def lstm(X):\n",
    "    \n",
    "    batch_size=tf.shape(X)[0]\n",
    "    time_step=tf.shape(X)[1]\n",
    "    \n",
    "    w_in=weights['in']\n",
    "    b_in=biases['in']\n",
    "    input=tf.reshape(X,[-1,input_size])  #需要将tensor转成2维进行计算，计算后的结果作为隐藏层的输入\n",
    "    input_rnn=tf.matmul(input,w_in)+b_in\n",
    "    input_rnn=tf.reshape(input_rnn,[-1,time_step,rnn_unit])  #将tensor转成3维，作为lstm cell的输入\n",
    "    \n",
    "    cell=tf.nn.rnn_cell.BasicLSTMCell(rnn_unit)\n",
    "    init_state=cell.zero_state(batch_size,dtype=tf.float32)\n",
    "    \n",
    "    output_rnn,final_states=tf.nn.dynamic_rnn(cell, input_rnn,initial_state=init_state, dtype=tf.float32)\n",
    "    output=tf.reshape(output_rnn,[-1,rnn_unit]) \n",
    "    w_out=weights['out']\n",
    "    b_out=biases['out']\n",
    "    \n",
    "    pred=tf.matmul(output,w_out)+b_out\n",
    "    return pred,final_states\n",
    "\n",
    "#————————————————訓練模型————————————————————\n",
    "\n",
    "def train_lstm(batch_size=6,time_step=3,train_begin=0,train_end=3960):\n",
    "    X=tf.placeholder(tf.float32, shape=[None,time_step,input_size])\n",
    "    Y=tf.placeholder(tf.float32, shape=[None,time_step,output_size])\n",
    "    batch_index,train_x,train_y=get_train_data(batch_size,time_step,train_begin,train_end)\n",
    "    with tf.variable_scope(\"sec_lstm\"):\n",
    "        pred,final_states=lstm(X)\n",
    "    loss=tf.reduce_mean(tf.square(tf.reshape(pred,[-1])-tf.reshape(Y, [-1])))\n",
    "    train_op=tf.train.RMSPropOptimizer(lr).minimize(loss)\n",
    "    saver=tf.train.Saver(tf.global_variables(),max_to_keep=15) #保存模型\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for i in range(200):     #迭代次數\n",
    "            for step in range(len(batch_index)-1):\n",
    "                _,loss_=sess.run([train_op,loss],feed_dict={X:train_x[batch_index[step]:batch_index[step+1]],Y:train_y[batch_index[step]:batch_index[step+1]]})\n",
    "            if i % 25 == 0:\n",
    "                print(\"Number of iterations:\",i,\" loss:\",loss_)\n",
    "            \n",
    "        print(\"model_save: \",saver.save(sess,'model_save2\\\\modle.ckpt'))\n",
    "        print(\"The train has finished\")\n",
    "train_lstm()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model_save2\\modle.ckpt\n",
      "The accuracy of this predict: 0.67931547619\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#————————————————預測模型————————————————————\n",
    "def prediction(time_step=3):\n",
    "    X=tf.placeholder(tf.float32, shape=[None,time_step,input_size])\n",
    "    mean,std,test_x,test_y=get_test_data(time_step)\n",
    "    with tf.variable_scope(\"sec_lstm\",reuse=True):\n",
    "        pred,_=lstm(X)\n",
    "    saver=tf.train.Saver(tf.global_variables())\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        module_file = tf.train.latest_checkpoint('model_save2')\n",
    "        saver.restore(sess, module_file)\n",
    "        test_predict=[]\n",
    "        for step in range(len(test_x)-1):\n",
    "          prob=sess.run(pred,feed_dict={X:[test_x[step]]})\n",
    "          predict=prob.reshape((-1))\n",
    "          test_predict.extend(predict)\n",
    "        test_y=np.array(test_y)\n",
    "        test_predict=np.array(test_predict)     \n",
    "        test_predict_2 = []\n",
    "        for ans in test_predict:\n",
    "            if ans >= 0.5:\n",
    "                test_predict_2.append(1)\n",
    "            else:\n",
    "                test_predict_2.append(0)\n",
    "        test_predict = test_predict_2\n",
    "        acc=1-sum(np.abs(test_predict-test_y[:len(test_predict)]))/len(test_predict)  #偏差程度\n",
    "        print(\"The accuracy of this predict:\",acc)\n",
    "\n",
    "prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable sec_lstm/rnn/basic_lstm_cell/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d040f087d759>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model_save: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'model_save2\\\\modle.ckpt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The train has finished\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m \u001b[0mtrain_lstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-d040f087d759>\u001b[0m in \u001b[0;36mtrain_lstm\u001b[1;34m(batch_size, time_step, train_begin, train_end)\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_train_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_begin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_end\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sec_lstm\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfinal_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[0mtrain_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRMSPropOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-d040f087d759>\u001b[0m in \u001b[0;36mlstm\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[0minit_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[0moutput_rnn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfinal_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_rnn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m     \u001b[0moutput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_rnn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrnn_unit\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[0mw_out\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'out'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[1;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[0;32m    612\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 614\u001b[1;33m         dtype=dtype)\n\u001b[0m\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m     \u001b[1;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[1;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[0;32m    775\u001b[0m       \u001b[0mloop_vars\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_ta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m       \u001b[0mparallel_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m       swap_memory=swap_memory)\n\u001b[0m\u001b[0;32m    778\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m   \u001b[1;31m# Unpack final output if not using output tuples.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name)\u001b[0m\n\u001b[0;32m   2814\u001b[0m     \u001b[0mloop_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWhileContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mback_prop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswap_memory\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=redefined-outer-name\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2815\u001b[0m     \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2816\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBuildLoop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloop_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape_invariants\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2817\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[1;34m(self, pred, body, loop_vars, shape_invariants)\u001b[0m\n\u001b[0;32m   2638\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEnter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2639\u001b[0m       original_body_result, exit_vars = self._BuildLoop(\n\u001b[1;32m-> 2640\u001b[1;33m           pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[0;32m   2641\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2642\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[1;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[0;32m   2588\u001b[0m         \u001b[0mstructure\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moriginal_loop_vars\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2589\u001b[0m         flat_sequence=vars_for_body_with_tensor_arrays)\n\u001b[1;32m-> 2590\u001b[1;33m     \u001b[0mbody_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2591\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2592\u001b[0m       \u001b[0mbody_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36m_time_step\u001b[1;34m(time, output_ta_t, state)\u001b[0m\n\u001b[0;32m    760\u001b[0m           skip_conditionals=True)\n\u001b[0;32m    761\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m       \u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;31m# Pack state if using state tuples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m     \u001b[0minput_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflat_sequence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 748\u001b[1;33m     \u001b[0mcall_cell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    749\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, state, scope)\u001b[0m\n\u001b[0;32m    181\u001b[0m       with vs.variable_scope(vs.get_variable_scope(),\n\u001b[0;32m    182\u001b[0m                              custom_getter=self._rnn_get_variable):\n\u001b[1;32m--> 183\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNNCell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_rnn_get_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    573\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0min_graph_mode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, state)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_linear\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_linear\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Linear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_units\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m     \u001b[1;31m# i = input_gate, j = new_input, f = forget_gate, o = output_gate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m     i, j, f, o = array_ops.split(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, output_size, build_bias, bias_initializer, kernel_initializer)\u001b[0m\n\u001b[0;32m   1169\u001b[0m           \u001b[0m_WEIGHTS_VARIABLE_NAME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtotal_arg_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1170\u001b[0m           \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1171\u001b[1;33m           initializer=kernel_initializer)\n\u001b[0m\u001b[0;32m   1172\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mbuild_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1173\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mvs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouter_scope\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minner_scope\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[0;32m   1201\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m       \u001b[0muse_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1203\u001b[1;33m       constraint=constraint)\n\u001b[0m\u001b[0;32m   1204\u001b[0m get_variable_or_local_docstring = (\n\u001b[0;32m   1205\u001b[0m     \"\"\"%s\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[0;32m   1090\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m           \u001b[0muse_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1092\u001b[1;33m           constraint=constraint)\n\u001b[0m\u001b[0;32m   1093\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1094\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[0;32m    415\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;34m\"constraint\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mestimator_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[0mcustom_getter_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"constraint\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 417\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mcustom_getter_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    418\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m       return _true_getter(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\u001b[0m in \u001b[0;36m_rnn_get_variable\u001b[1;34m(self, getter, *args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_rnn_get_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m     \u001b[0mvariable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m       trainable = (variable in tf_variables.trainable_variables() or\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[1;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[0;32m    392\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m           use_resource=use_resource, constraint=constraint)\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[0;32m    740\u001b[0m                          \u001b[1;34m\"reuse=tf.AUTO_REUSE in VarScope? \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    741\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[1;32m--> 742\u001b[1;33m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[0;32m    743\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    744\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Variable sec_lstm/rnn/basic_lstm_cell/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n"
     ]
    }
   ],
   "source": [
    "###五期\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "rnn_unit=10       #隱藏數量(自訂)\n",
    "input_size=7 #BICPRFM\n",
    "output_size=1 #YN\n",
    "lr=0.0001         #學習率\n",
    "#——————————————————import data ——————————————————————\n",
    "f=open('2018_data_all_log.csv')\n",
    "df=pd.read_csv(f)     #讀入資料\n",
    "data=df.iloc[:,3:11].values  #取第3-10列(取頭不取尾)\n",
    "\n",
    "\n",
    "#獲取訓練集 (做標準化)\n",
    "def get_train_data(batch_size=10,time_step=5,train_begin=0,train_end=6600):\n",
    "    batch_index=[]\n",
    "    data_train=data[train_begin:train_end]\n",
    "    normalized_train_data=(data_train-np.mean(data_train,axis=0))/np.std(data_train,axis=0)  #標準化\n",
    "    train_x,train_y=[],[]   #訓練集\n",
    "    for i in range(len(normalized_train_data)-time_step):\n",
    "       if i % batch_size==0:\n",
    "           batch_index.append(i)\n",
    "       x=normalized_train_data[i:i+time_step,:7]\n",
    "       y=data_train[i:i+time_step,7,np.newaxis]\n",
    "       train_x.append(x.tolist())\n",
    "       train_y.append(y.tolist())\n",
    "    batch_index.append((len(normalized_train_data)-time_step))\n",
    "    return batch_index,train_x,train_y\n",
    "\n",
    "\n",
    "#測試集\n",
    "def get_test_data(time_step=5,test_begin=6600):\n",
    "    data_test=data[test_begin:]\n",
    "    mean=np.mean(data_test,axis=0)\n",
    "    std=np.std(data_test,axis=0)\n",
    "    normalized_test_data=(data_test-mean)/std  #標準化\n",
    "    size=(len(normalized_test_data)+time_step-1)//time_step  #有size個sample\n",
    "    test_x,test_y=[],[]\n",
    "    for i in range(size-1):\n",
    "       x=normalized_test_data[i*time_step:(i+1)*time_step,:7]\n",
    "       y=data_test[i*time_step:(i+1)*time_step,7]\n",
    "       test_x.append(x.tolist())\n",
    "       test_y.extend(y)\n",
    "    test_x.append((normalized_test_data[(i+1)*time_step:,:7]).tolist())\n",
    "    test_y.extend((data_test[(i+1)*time_step:,7]).tolist())\n",
    "    return mean,std,test_x,test_y\n",
    "\n",
    "\n",
    "#——————————————————定義神經網絡變量——————————————————\n",
    "#輸入層  輸出層權重  bias\n",
    "\n",
    "weights={\n",
    "         'in':tf.Variable(tf.random_normal([input_size,rnn_unit])),\n",
    "         'out':tf.Variable(tf.random_normal([rnn_unit,1]))\n",
    "        }\n",
    "biases={\n",
    "        'in':tf.Variable(tf.constant(0.1,shape=[rnn_unit,])),\n",
    "        'out':tf.Variable(tf.constant(0.1,shape=[1,]))\n",
    "       }\n",
    "\n",
    "#——————————————————定義lstm——————————————————\n",
    "def lstm(X):\n",
    "    \n",
    "    batch_size=tf.shape(X)[0]\n",
    "    time_step=tf.shape(X)[1]\n",
    "    \n",
    "    w_in=weights['in']\n",
    "    b_in=biases['in']\n",
    "    input=tf.reshape(X,[-1,input_size])  #需要将tensor转成2维进行计算，计算后的结果作为隐藏层的输入\n",
    "    input_rnn=tf.matmul(input,w_in)+b_in\n",
    "    input_rnn=tf.reshape(input_rnn,[-1,time_step,rnn_unit])  #将tensor转成3维，作为lstm cell的输入\n",
    "    \n",
    "    cell=tf.nn.rnn_cell.BasicLSTMCell(rnn_unit)\n",
    "    init_state=cell.zero_state(batch_size,dtype=tf.float32)\n",
    "    \n",
    "    output_rnn,final_states=tf.nn.dynamic_rnn(cell, input_rnn,initial_state=init_state, dtype=tf.float32)\n",
    "    output=tf.reshape(output_rnn,[-1,rnn_unit]) \n",
    "    w_out=weights['out']\n",
    "    b_out=biases['out']\n",
    "    \n",
    "    pred=tf.matmul(output,w_out)+b_out\n",
    "    return pred,final_states\n",
    "\n",
    "#————————————————訓練模型————————————————————\n",
    "\n",
    "def train_lstm(batch_size=10,time_step=5,train_begin=0,train_end=6600):\n",
    "    X=tf.placeholder(tf.float32, shape=[None,time_step,input_size])\n",
    "    Y=tf.placeholder(tf.float32, shape=[None,time_step,output_size])\n",
    "    batch_index,train_x,train_y=get_train_data(batch_size,time_step,train_begin,train_end)\n",
    "    with tf.variable_scope(\"sec_lstm\"):\n",
    "        pred,final_states=lstm(X)\n",
    "    loss=tf.reduce_mean(tf.square(tf.reshape(pred,[-1])-tf.reshape(Y, [-1])))\n",
    "    train_op=tf.train.RMSPropOptimizer(lr).minimize(loss)\n",
    "    saver=tf.train.Saver(tf.global_variables(),max_to_keep=15) #保存模型\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for i in range(200):     #迭代次數\n",
    "            for step in range(len(batch_index)-1):\n",
    "                _,loss_=sess.run([train_op,loss],feed_dict={X:train_x[batch_index[step]:batch_index[step+1]],Y:train_y[batch_index[step]:batch_index[step+1]]})\n",
    "            if i % 25 == 0:\n",
    "                print(\"Number of iterations:\",i,\" loss:\",loss_)\n",
    "            \n",
    "        print(\"model_save: \",saver.save(sess,'model_save2\\\\modle.ckpt'))\n",
    "        print(\"The train has finished\")\n",
    "train_lstm()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model_save2\\modle.ckpt\n",
      "The accuracy of this predict: 0.678125\n"
     ]
    }
   ],
   "source": [
    "#————————————————預測模型————————————————————\n",
    "def prediction(time_step=5):\n",
    "    X=tf.placeholder(tf.float32, shape=[None,time_step,input_size])\n",
    "    mean,std,test_x,test_y=get_test_data(time_step)\n",
    "    with tf.variable_scope(\"sec_lstm\",reuse=True):\n",
    "        pred,_=lstm(X)\n",
    "    saver=tf.train.Saver(tf.global_variables())\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        module_file = tf.train.latest_checkpoint('model_save2')\n",
    "        saver.restore(sess, module_file)\n",
    "        test_predict=[]\n",
    "        for step in range(len(test_x)-1):\n",
    "          prob=sess.run(pred,feed_dict={X:[test_x[step]]})\n",
    "          predict=prob.reshape((-1))\n",
    "          test_predict.extend(predict)\n",
    "        test_y=np.array(test_y)\n",
    "        test_predict=np.array(test_predict)     \n",
    "        test_predict_2 = []\n",
    "        for ans in test_predict:\n",
    "            if ans >= 0.5:\n",
    "                test_predict_2.append(1)\n",
    "            else:\n",
    "                test_predict_2.append(0)\n",
    "        test_predict = test_predict_2\n",
    "        acc=1-sum(np.abs(test_predict-test_y[:len(test_predict)]))/len(test_predict)  #偏差程度\n",
    "        print(\"The accuracy of this predict:\",acc)\n",
    "\n",
    "prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
